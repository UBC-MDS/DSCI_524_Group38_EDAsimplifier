[
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nThis Code of Conduct applies to all interactions related to this project, including GitHub issues, pull requests, code reviews, project boards, documentation, and any other project-related communication.\n\n\n\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting\n\n\n\n\nCommunity leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\nFor this project, community leaders refer to the core project contributors and maintainers as listed in the repository.\n\n\n\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. This Code of Conduct also applies to all academic and collaborative activities associated with this project.\n\n\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the project maintainers via GitHub issues or private communication as agreed upon by the team. If the issue cannot be resolved internally, it may be escalated to course instructors or teaching assistants.\nAll complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident.\n\n\n\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community.\n\n\n\n\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-pledge",
    "href": "CODE_OF_CONDUCT.html#our-pledge",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.\nThis Code of Conduct applies to all interactions related to this project, including GitHub issues, pull requests, code reviews, project boards, documentation, and any other project-related communication."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#our-standards",
    "href": "CODE_OF_CONDUCT.html#our-standards",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Examples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "href": "CODE_OF_CONDUCT.html#enforcement-responsibilities",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.\nFor this project, community leaders refer to the core project contributors and maintainers as listed in the repository."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#scope",
    "href": "CODE_OF_CONDUCT.html#scope",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. This Code of Conduct also applies to all academic and collaborative activities associated with this project."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement",
    "href": "CODE_OF_CONDUCT.html#enforcement",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the project maintainers via GitHub issues or private communication as agreed upon by the team. If the issue cannot be resolved internally, it may be escalated to course instructors or teaching assistants.\nAll complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "href": "CODE_OF_CONDUCT.html#enforcement-guidelines",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\n\nCommunity Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\nConsequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.\n\n\n\nCommunity Impact: A violation through a single incident or series of actions.\nConsequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nCommunity Impact: A serious violation of community standards, including sustained inappropriate behavior.\nConsequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nCommunity Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\nConsequence: A permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "CODE_OF_CONDUCT.html#attribution",
    "href": "CODE_OF_CONDUCT.html#attribution",
    "title": "Contributor Covenant Code of Conduct",
    "section": "",
    "text": "This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq. Translations are available at https://www.contributor-covenant.org/translations."
  },
  {
    "objectID": "reference/simplify.all_distributions.html",
    "href": "reference/simplify.all_distributions.html",
    "title": "simplify.all_distributions",
    "section": "",
    "text": "simplify.all_distributions(\n    pd_dataframe,\n    target_column,\n    categorical_target,\n    max_categories=10,\n    categorical_features=None,\n    ambiguous_column_types=None,\n)\nGenerate distribution visualizations (e.g., histograms and bar charts) for numeric and categorical columns in a DataFrame.\nThis is the main function for column-level EDA distribution visualizations. The function automatically infers whether columns are numeric or categorical. Allows manual overrides for ambiguous columns, ambiguous columns are cases where a numeric datatype column should be treated as categorical or vice versa.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npd_dataframe\npandas.DataFrame\nInput DataFrame containing the data to be analyzed. Expects a tidy dataframe (one value or string per cell) but can handle some common messy data issue such as incorrect datatypes via ambiguous_column_types parameter.\nrequired\n\n\ntarget_column\nstr\nThe name of the target column. Funneled to all subfunctions.\nrequired\n\n\ncategorical_target\nbool\nA boolean value indicating if the target column is categorical or not.\nrequired\n\n\nmax_categories\nint\nThe maximum categories to plot for high cardinality features. Funneled to categorical_plot function\n10\n\n\ncategorical_features\nlist\nSubset of columns to use for categorical plots. If this is not passed, keep all. Subset of columns to include in the analysis. Invalid or non-existent column names are ignored.\nNone\n\n\nambiguous_column_types\ndict\nDictionary specifying column type overrides for ambiguous cases. Expected keys are \"numeric\" and \"categorical\", with values being lists of column names to force into each category. If a column appears in both lists, will raise a ValueError. Invalid or non-existent column names are ignored. Example: ambiguous_column_types = {“numeric” : [‘year’], “categorical”: [’zip_code]}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nThis function produces distribution plots as a side effect and returns a dictionary of plots types: {“numeric” : cat_plots, “categorical”: numeric_plots}. Currently the categorical_plots contains plots in the form of an appended plot object / list, and numeric_plots contains plots organized in a dictionary according to plot type.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'age': [25, 30, 35, 40, 45],\n...     'income': [50000, 60000, 75000, 80000, 90000],\n...     'city': ['NYC', 'LA', 'Chicago', 'NYC', 'LA'],\n...     'approved': ['Yes', 'No', 'Yes', 'Yes', 'No']\n... })\n&gt;&gt;&gt; plots = all_distributions(\n...     pd_dataframe=df,\n...     target_column='approved',\n...     categorical_target=True\n... )\n&gt;&gt;&gt; plots.keys()\ndict_keys(['numeric', 'categorical'])\n&gt;&gt;&gt; numeric_plots = plots['numeric']\n&gt;&gt;&gt; categorical_plots = plots['categorical']"
  },
  {
    "objectID": "reference/simplify.all_distributions.html#parameters",
    "href": "reference/simplify.all_distributions.html#parameters",
    "title": "simplify.all_distributions",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npd_dataframe\npandas.DataFrame\nInput DataFrame containing the data to be analyzed. Expects a tidy dataframe (one value or string per cell) but can handle some common messy data issue such as incorrect datatypes via ambiguous_column_types parameter.\nrequired\n\n\ntarget_column\nstr\nThe name of the target column. Funneled to all subfunctions.\nrequired\n\n\ncategorical_target\nbool\nA boolean value indicating if the target column is categorical or not.\nrequired\n\n\nmax_categories\nint\nThe maximum categories to plot for high cardinality features. Funneled to categorical_plot function\n10\n\n\ncategorical_features\nlist\nSubset of columns to use for categorical plots. If this is not passed, keep all. Subset of columns to include in the analysis. Invalid or non-existent column names are ignored.\nNone\n\n\nambiguous_column_types\ndict\nDictionary specifying column type overrides for ambiguous cases. Expected keys are \"numeric\" and \"categorical\", with values being lists of column names to force into each category. If a column appears in both lists, will raise a ValueError. Invalid or non-existent column names are ignored. Example: ambiguous_column_types = {“numeric” : [‘year’], “categorical”: [’zip_code]}\nNone"
  },
  {
    "objectID": "reference/simplify.all_distributions.html#returns",
    "href": "reference/simplify.all_distributions.html#returns",
    "title": "simplify.all_distributions",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nThis function produces distribution plots as a side effect and returns a dictionary of plots types: {“numeric” : cat_plots, “categorical”: numeric_plots}. Currently the categorical_plots contains plots in the form of an appended plot object / list, and numeric_plots contains plots organized in a dictionary according to plot type."
  },
  {
    "objectID": "reference/simplify.all_distributions.html#examples",
    "href": "reference/simplify.all_distributions.html#examples",
    "title": "simplify.all_distributions",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'age': [25, 30, 35, 40, 45],\n...     'income': [50000, 60000, 75000, 80000, 90000],\n...     'city': ['NYC', 'LA', 'Chicago', 'NYC', 'LA'],\n...     'approved': ['Yes', 'No', 'Yes', 'Yes', 'No']\n... })\n&gt;&gt;&gt; plots = all_distributions(\n...     pd_dataframe=df,\n...     target_column='approved',\n...     categorical_target=True\n... )\n&gt;&gt;&gt; plots.keys()\ndict_keys(['numeric', 'categorical'])\n&gt;&gt;&gt; numeric_plots = plots['numeric']\n&gt;&gt;&gt; categorical_plots = plots['categorical']"
  },
  {
    "objectID": "reference/simplify.dataset_overview.html",
    "href": "reference/simplify.dataset_overview.html",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "simplify.dataset_overview(df)\nGenerates a consolidated exploratory summary of the dataset.\nThis function provides a single, high level overview of the dataset by combining commonly used exploratory data analysis (EDA) outputs such as dataset dimensions, column data types, missing value counts, and descriptive statistics. It is intended to simplify the initial EDA process by replacing multiple pandas method calls (e.g., .info(), .describe(), .shape) with one function.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas dataFrame containing the dataset to be summarized.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nA dictionary with the following fixed structure: - “shape” : tuple[int, int] Number of rows and columns in the DataFrame. - “columns” : list[str] List of column names, in the order they appear in the DataFrame. - “dtypes” : dict[str, str] Mapping of column names to their pandas data types (as strings). - “missing_values” : dict[str, int] Count of missing (NaN) values per column. - “summary_statistics” : dict[str, pandas.Series] Descriptive statistics for numeric columns only, as returned by pandas.DataFrame.describe().\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf the input provided is not a pandas dataFrame.\n\n\n\n\n\n\n\nThis function does not modify the input DataFrame.\nIf the DataFrame is empty, all returned values will be empty but valid.\nIf the DataFrame contains no numeric columns, “summary_statistics” will be an empty dictionary.\nThe returned dictionary follows a fixed structure to support deterministic unit testing.\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"artist\": [\"A\", \"B\", \"C\"],\n...     \"popularity\": [80, 75, None],\n...     \"danceability\": [0.8, 0.6, 0.9]\n... })\n&gt;&gt;&gt; dataset_overview(df)\n{\n    \"shape\": (3, 3),\n    \"columns\": [\"artist\", \"popularity\", \"danceability\"],\n    \"dtypes\": {\n        \"artist\": \"object\",\n        \"popularity\": \"float\",\n        \"danceability\": \"float\"\n    },\n    \"missing_values\": {\n        \"artist\": 0,\n        \"popularity\": 1,\n        \"danceability\": 0\n    },\n    \"summary_statistics\": {\n        \"popularity\": {...},\n        \"danceability\": {...}\n    }\n}"
  },
  {
    "objectID": "reference/simplify.dataset_overview.html#parameters",
    "href": "reference/simplify.dataset_overview.html#parameters",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas dataFrame containing the dataset to be summarized.\nrequired"
  },
  {
    "objectID": "reference/simplify.dataset_overview.html#returns",
    "href": "reference/simplify.dataset_overview.html#returns",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nA dictionary with the following fixed structure: - “shape” : tuple[int, int] Number of rows and columns in the DataFrame. - “columns” : list[str] List of column names, in the order they appear in the DataFrame. - “dtypes” : dict[str, str] Mapping of column names to their pandas data types (as strings). - “missing_values” : dict[str, int] Count of missing (NaN) values per column. - “summary_statistics” : dict[str, pandas.Series] Descriptive statistics for numeric columns only, as returned by pandas.DataFrame.describe()."
  },
  {
    "objectID": "reference/simplify.dataset_overview.html#raises",
    "href": "reference/simplify.dataset_overview.html#raises",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nTypeError\nIf the input provided is not a pandas dataFrame."
  },
  {
    "objectID": "reference/simplify.dataset_overview.html#notes",
    "href": "reference/simplify.dataset_overview.html#notes",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "This function does not modify the input DataFrame.\nIf the DataFrame is empty, all returned values will be empty but valid.\nIf the DataFrame contains no numeric columns, “summary_statistics” will be an empty dictionary.\nThe returned dictionary follows a fixed structure to support deterministic unit testing."
  },
  {
    "objectID": "reference/simplify.dataset_overview.html#examples",
    "href": "reference/simplify.dataset_overview.html#examples",
    "title": "simplify.dataset_overview",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"artist\": [\"A\", \"B\", \"C\"],\n...     \"popularity\": [80, 75, None],\n...     \"danceability\": [0.8, 0.6, 0.9]\n... })\n&gt;&gt;&gt; dataset_overview(df)\n{\n    \"shape\": (3, 3),\n    \"columns\": [\"artist\", \"popularity\", \"danceability\"],\n    \"dtypes\": {\n        \"artist\": \"object\",\n        \"popularity\": \"float\",\n        \"danceability\": \"float\"\n    },\n    \"missing_values\": {\n        \"artist\": 0,\n        \"popularity\": 1,\n        \"danceability\": 0\n    },\n    \"summary_statistics\": {\n        \"popularity\": {...},\n        \"danceability\": {...}\n    }\n}"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Function reference",
    "section": "",
    "text": "Functions to help you quickly and easily get high-level EDA visuals\n\n\n\nsimplify.dataset_overview\nGenerates a consolidated exploratory summary of the dataset.\n\n\nsimplify.numeric\nPerform exploratory data analysis (EDA) on numerical features in a dataset.\n\n\nsimplify.categorical_plot\nPerform EDA on categorical columns in a dataset.\n\n\nsimplify.all_distributions\nGenerate distribution visualizations (e.g., histograms and bar charts) for numeric\n\n\nsimplify._ambiguous_columns_split\nSeparates numeric and categorical columns for a pandas Dataframe,"
  },
  {
    "objectID": "reference/index.html#eda-tools-simplified",
    "href": "reference/index.html#eda-tools-simplified",
    "title": "Function reference",
    "section": "",
    "text": "Functions to help you quickly and easily get high-level EDA visuals\n\n\n\nsimplify.dataset_overview\nGenerates a consolidated exploratory summary of the dataset.\n\n\nsimplify.numeric\nPerform exploratory data analysis (EDA) on numerical features in a dataset.\n\n\nsimplify.categorical_plot\nPerform EDA on categorical columns in a dataset.\n\n\nsimplify.all_distributions\nGenerate distribution visualizations (e.g., histograms and bar charts) for numeric\n\n\nsimplify._ambiguous_columns_split\nSeparates numeric and categorical columns for a pandas Dataframe,"
  },
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing",
    "section": "",
    "text": "This repository is developed as part of a collaborative, course based software development project. Contributions are primarily made by student team members following an agreed-upon workflow and milestone plan. External contributions are welcome but may be reviewed within the constraints of the course timeline. All contributions must follow and accept the Code of Conduct.\n\n\nYou can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/eda_simplifier/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on an issue, please assign yourself to it. For this project, each core feature or function should be owned by a single team member to ensure equal contribution across the team.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nEDA_simplifier could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/eda_simplifier/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time.\n\n\n\n\nReady to contribute? Here’s how to set up EDA_simplifier for local development.\n\nFork the https://github.com/UBC-MDS/eda_simplifier repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/eda_simplifier.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request.\n\n\n\n\nThis project follows a GitHub Flow–based workflow:\n\nAll work is tracked through GitHub issues\nNew work is done on feature or fix branches created from main\nAll changes must be submitted via pull requests\nEach pull request should be reviewed by at least one other team member before merging\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests when functionality is implemented. Documentation-only changes (e.g., Milestone 1 specifications) are not expected to include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging.\nFor early milestones, function docstrings serve as formal specifications and may exist without an implementation."
  },
  {
    "objectID": "CONTRIBUTING.html#example-contributions",
    "href": "CONTRIBUTING.html#example-contributions",
    "title": "Contributing",
    "section": "",
    "text": "You can contribute in many ways, for example:\n\nReport bugs\nFix Bugs\nImplement Features\nWrite Documentation\nSubmit Feedback\n\n\n\nReport bugs at https://github.com/UBC-MDS/eda_simplifier/issues.\nIf you are reporting a bug, please follow the template guidelines. The more detailed your report, the easier and thus faster we can help you.\n\n\n\nLook through the GitHub issues for bugs. Anything labelled with bug and help wanted is open to whoever wants to implement it. When you decide to work on an issue, please assign yourself to it. For this project, each core feature or function should be owned by a single team member to ensure equal contribution across the team.\n\n\n\nLook through the GitHub issues for features. Anything labelled with enhancement and help wanted is open to whoever wants to implement it. As for fixing bugs, please assign yourself to the issue and add a comment that you’ll be working on that, too. If another enhancement catches your fancy, but it doesn’t have the help wanted label, just post a comment, the maintainers are usually happy for any support that they can get.\n\n\n\nEDA_simplifier could always use more documentation, whether as part of the official documentation, in docstrings, or even on the web in blog posts, articles, and such. Just open an issue to let us know what you will be working on so that we can provide you with guidance.\n\n\n\nThe best way to send feedback is to file an issue at https://github.com/UBC-MDS/eda_simplifier/issues. If your feedback fits the format of one of the issue templates, please use that. Remember that this is a volunteer-driven project and everybody has limited time."
  },
  {
    "objectID": "CONTRIBUTING.html#get-started",
    "href": "CONTRIBUTING.html#get-started",
    "title": "Contributing",
    "section": "",
    "text": "Ready to contribute? Here’s how to set up EDA_simplifier for local development.\n\nFork the https://github.com/UBC-MDS/eda_simplifier repository on GitHub.\nClone your fork locally (if you want to work locally)\ngit clone git@github.com:your_name_here/eda_simplifier.git\nInstall hatch.\nCreate a branch for local development using the default branch (typically main) as a starting point. Use fix or feat as a prefix for your branch name.\ngit checkout main\ngit checkout -b fix-name-of-your-bugfix\nNow you can make your changes locally.\nWhen you’re done making changes, apply the quality assurance tools and check that your changes pass our test suite. This is all included with tox\nhatch run test:run\nCommit your changes and push your branch to GitHub. Please use semantic commit messages.\ngit add .\ngit commit -m \"fix: summarize your changes\"\ngit push -u origin fix-name-of-your-bugfix\nOpen the link displayed in the message when pushing your new branch in order to submit a pull request."
  },
  {
    "objectID": "CONTRIBUTING.html#development-workflow",
    "href": "CONTRIBUTING.html#development-workflow",
    "title": "Contributing",
    "section": "",
    "text": "This project follows a GitHub Flow–based workflow:\n\nAll work is tracked through GitHub issues\nNew work is done on feature or fix branches created from main\nAll changes must be submitted via pull requests\nEach pull request should be reviewed by at least one other team member before merging\n\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\nThe pull request should include tests when functionality is implemented. Documentation-only changes (e.g., Milestone 1 specifications) are not expected to include tests.\nIf the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring.\nYour pull request will automatically be checked by the full test suite. It needs to pass all of them before it can be considered for merging.\nFor early milestones, function docstrings serve as formal specifications and may exist without an implementation."
  },
  {
    "objectID": "CHANGELOG.html",
    "href": "CHANGELOG.html",
    "title": "Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file.\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning.\n\n\n\nUpcoming features and fixes\n\n\n\n\n\nFirst release"
  },
  {
    "objectID": "CHANGELOG.html#unreleased",
    "href": "CHANGELOG.html#unreleased",
    "title": "Changelog",
    "section": "",
    "text": "Upcoming features and fixes"
  },
  {
    "objectID": "CHANGELOG.html#section",
    "href": "CHANGELOG.html#section",
    "title": "Changelog",
    "section": "",
    "text": "First release"
  },
  {
    "objectID": "DEVELOPMENT.html",
    "href": "DEVELOPMENT.html",
    "title": "Development Guide",
    "section": "",
    "text": "Welcome to your shiny new package. This page will help you get started with using Hatch to manage your package.\nIf you look at your project, you will see that a pyproject.toml file. This file stores both your package configuration and settings for development tools like Hatch that you will use to work on your package.\nThis file is written using a .toml format. You can learn more about toml here. Here’s the TL&DR:\n\nEach [] section in the toml file is called a table.\nYou can nest tables with double brackets like this[[]]\nTables contain information about a element that you want to configure.\n\nWe are using Hatch as the default packaging tool. Hatch allows you to configure and run environments and scripts similar to workflow tools like tox or nox.\nHach, by default, uses virtual environments (venv) to manage environments. But you can configure it to use other environment tools.Read the hatch documentation to learn more about environments.\nFor this template, we have set up Hatch environments for you to use. At the bottom of your pyproject.toml file, notice a hatch environment section that looks like this:\n########################################\n# Hatch Environments\n########################################\nBelow is the Hatch environment to install your package. Notice that it defines pip and twine as two packages that the environment needs.\n[tool.hatch.envs.build]\ndescription = \"\"\"Test the installation the package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\nThe table below defines the scripts that you will run build and check your package.\n[tool.hatch.envs.build.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\ndetached = true\nYou can enter that environment to check it out:\n$ hatch shell build\nIf you run pip list, in the environment, twine will be there:\n$ pip list\nHatch by default, installs your package in editable mode (-e) into its virtual environments. But if detached=True is set, then it will skip installing your package into the virtual enviornment.\n\n\nBelow you see the Hatch environment test table.\ntool.hatch.envs says, “Hey, Hatch, this is the definition for an environment.” test is the name of the environment.\nThe environment below defines the dependencies that Hatch needs to install into the environment named test.\n[tool.hatch.envs.test]\ndescription = \"\"\"Run the test suite.\"\"\"\ndependencies = [\n    \"pytest\",\n    \"pytest-cov\",\n    \"pytest-raises\",\n    \"pytest-randomly\",\n    \"pytest-xdist\",\n]\nTo enter a Hatch environment use:\nhatch shell environmentname\nSo you can enter the test environment above with:\nhatch shell test\n\n\n\nIf the environment has a matrix associated with it, that tells Hatch to run the test scripts across different Python versions.\n[[tool.hatch.envs.test.matrix]]\npython = [\"3.10\", \"3.11\", \"3.12\", \"3.13\"]\nIf you run hatch shell test, you will see the output below. To enter an environment with a matrix attached to it, you need to pick the Python environment version that you want to open.\n$ hatch shell test                           \nEnvironment `test` defines a matrix, choose one of the following instead:\n\ntest.py3.10\ntest.py3.11\ntest.py3.12\ntest.py3.13\nOpen the Python 3.13 environment like this:\n$ hatch shell test.py3.13\nTo leave an environment use:\n$ deactivate\n\n\n\nIn the tests section of your pyproject.toml, you will see a tool.hatch.envs.test.scripts table.\nThis table defines the commands that you want Hatch to run in the test environment. Notice that the script has one command called run.\n[tool.hatch.envs.test.scripts]\nrun = \"pytest {args:--cov=greatproject --cov-report=term-missing}\"\nTo run this script , use:\nhatch run test:run\n\nhatch run: calls Hatch and tells it that it will be running a command\ntest:run: defines the environment you want it to run (test) and defines the name of the “script” to berun.\n\nIf you have a Hatch matrix setup for tests, it will both install the necessary Python version using UV and run your tests on each version of the Python versions that you declare in the matrix table. In this case, there are 4 Python versions in the environment, so your tests will run 4 times, once in each Python version listed in the matrix table.\n@lwasser ➜ /workspaces/pyopensci-scipy25-create-python-package (main) $ hatch run test:run\n──────────────────────────────────────────────────────────────────────── test.py3.10 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.10.16, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1490740387\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.10.16-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n──────────────────────────────────────────────────────────────────────── test.py3.11 ────────────────────────────────────────────────────────────────────────\n==================================================================== test session starts ====================================================================\nplatform linux -- Python 3.11.12, pytest-8.4.1, pluggy-1.6.0\nUsing --randomly-seed=1596865075\nrootdir: /workspaces/pyopensci-scipy25-create-python-package\nconfigfile: pyproject.toml\ntestpaths: tests\nplugins: xdist-3.8.0, randomly-3.16.0, raises-0.11, cov-6.2.1\ncollected 2 items                                                                                                                                           \n\ntests/system/test_import.py .                                                                                                                         [ 50%]\ntests/unit/test_example.py .                                                                                                                          [100%]\n\n====================================================================== tests coverage =======================================================================\n_____________________________________________________ coverage: platform linux, python 3.11.12-final-0 ______________________________________________________\n\nName                           Stmts   Miss Branch BrPart    Cover   Missing\n----------------------------------------------------------------------------\nsrc/greatproject/__init__.py       0      0      0      0  100.00%\nsrc/greatproject/example.py        2      0      0      0  100.00%\n----------------------------------------------------------------------------\nTOTAL                              2      0      0      0  100.00%\n===================================================================== 2 passed in 0.05s =====================================================================\n\n\n\nYou can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "DEVELOPMENT.html#build-your-package",
    "href": "DEVELOPMENT.html#build-your-package",
    "title": "Development Guide",
    "section": "",
    "text": "You can build your package using the environment and scripts defined in the build tables:\nhatch run build:check\nThis script builds and checks the output distribution files of your package.\nThis build environment table declares that pip and twine should be added to that environment. Adding pip to the environment ensures that it is a current, up-to-date version.\n[tool.hatch.envs.build]\ndescription = \"\"\"Build and test your package.\"\"\"\ndependencies = [\n    \"pip\",\n    \"twine\",\n]\ndetached = true\n# This table installs created the command hatch run install:check which will build and check your package.\n[tool.hatch.envs.install.scripts]\ncheck = [\n    \"pip check\",\n    \"hatch build {args:--clean}\",\n    \"twine check dist/*\",\n]\nThis uses the above environment and tells hatch to run\n\npip check, # verifies your dependencies\nhatch build --clean\n\ntwine check dist/* # this checks your distribution for metadata and other potential issues. to build and test your package."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "Package\n \n\n\nMeta\n\n\n\n\nTODO: the above badges that indicate python version and package version will only work if your package is on PyPI. If you don’t plan to publish to PyPI, you can remove them.\n\n\nEDA_simplifier is a project that streamlines exploratory data analysis (EDA) for any pandas DataFrame. This package provides functions that consolidate many repetitive steps in EDA, serving as a first pass to quickly gain a holistic view of a dataset. Within the larger Python ecosystem, it requires Pandas and primarily builds upon Altair. While Altair is powerful, it can also be verbose and syntactically restrictive. As a result, many functions in this project act as wrappers around Altair, providing sensible defaults and abstractions to simplify the EDA process. Although automated EDA reporting libraries exist, most focus on large-scale HTML reports or one-liner summaries. Therefore the EDA simplifier package provides a intermediate between raw Altair-based EDA plotting and full-automated report libraries.\n\n\n\n\ndataset_overview: Generates a consolidated exploratory summary of a dataset by combining key information typically obtained from multiple pandas methods such as .info(), .describe(), and .shape. The function returns the dataset dimensions, column data types, missing value counts, and summary statistics in a single simplified structure to streamline the initial exploratory data analysis process.\nnumeric: Perform exploratory data analysis (EDA) on numerical features in a dataset. Generates visualizations for specified numerical columns to help with initial exploratory analysis. It produces histogram plots to examine distributions, correlation plots to identify relationships between features, missing values, and other relevant numerical summaries.\ncategorical_plot: Creates Altair plots for the specified categorical columns. Creates bar charts and pie charts for each features. Also create box plots or stacked bar charts for each feature against the target depending on if the target is categorical or numerical.\nall_distributions: The main interface for column-level EDA distribution visualizations for numeric and categorical columns. Automatically identifies each columns data types and routes them to the appropriate plotting functions (numeric and categorical_plot). Also includes a manual overrides for ambiguous columns via explicit user input where the default columns data types may be incorrectly represented (using the hidden _ambiguous_columns_split function).\n_ambiguous_columns_split: Separates numeric and categorical columns for a pandas Dataframe, and applies overrides for ambiguous cases via input. Hidden function used purely for all_distributions function.\n\n\n\n\nYou can install this package into your preferred Python environment:\n# create a new empty conda environment with Python 3.11 (and pip by proxy):\nconda create -n eda_simplifier python=3.11 \n# activate the new environment\nconda activate eda_simplifier \nTo verify the package passes all the unit tests:\n# To install and use package (in edit mode with dev dependencies):\npip install -e \".[dev]\"  \n# Run unit tests:\npytest -v\n\n# Deactivate the conda environment when done:\nconda deactivate\nTODO: Add a brief example of how to use the package to this section\nTo use eda_simplifier in your code:\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from eda_simplifier.simplify import dataset_overview\n\n&gt;&gt;&gt; df = pd.DataFrame({\n    \"artist\": [\"A\", \"B\", \"C\"],\n    \"popularity\": [80, 75, None],\n    \"danceability\": [0.8, 0.6, 0.9]\n})\n\n&gt;&gt;&gt; summary = dataset_overview(df)\n\n\n\n\nDiana Cornescu\nJohnson Chuang\nLavanya Gupta\nTiantong Yin\n\n\n\n\n\nCopyright © Diana Cornescu, Johnson Chuang, Lavanya Gupta & Tiantong Yin.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "index.html#package-summary",
    "href": "index.html#package-summary",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "EDA_simplifier is a project that streamlines exploratory data analysis (EDA) for any pandas DataFrame. This package provides functions that consolidate many repetitive steps in EDA, serving as a first pass to quickly gain a holistic view of a dataset. Within the larger Python ecosystem, it requires Pandas and primarily builds upon Altair. While Altair is powerful, it can also be verbose and syntactically restrictive. As a result, many functions in this project act as wrappers around Altair, providing sensible defaults and abstractions to simplify the EDA process. Although automated EDA reporting libraries exist, most focus on large-scale HTML reports or one-liner summaries. Therefore the EDA simplifier package provides a intermediate between raw Altair-based EDA plotting and full-automated report libraries."
  },
  {
    "objectID": "index.html#functions",
    "href": "index.html#functions",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "dataset_overview: Generates a consolidated exploratory summary of a dataset by combining key information typically obtained from multiple pandas methods such as .info(), .describe(), and .shape. The function returns the dataset dimensions, column data types, missing value counts, and summary statistics in a single simplified structure to streamline the initial exploratory data analysis process.\nnumeric: Perform exploratory data analysis (EDA) on numerical features in a dataset. Generates visualizations for specified numerical columns to help with initial exploratory analysis. It produces histogram plots to examine distributions, correlation plots to identify relationships between features, missing values, and other relevant numerical summaries.\ncategorical_plot: Creates Altair plots for the specified categorical columns. Creates bar charts and pie charts for each features. Also create box plots or stacked bar charts for each feature against the target depending on if the target is categorical or numerical.\nall_distributions: The main interface for column-level EDA distribution visualizations for numeric and categorical columns. Automatically identifies each columns data types and routes them to the appropriate plotting functions (numeric and categorical_plot). Also includes a manual overrides for ambiguous columns via explicit user input where the default columns data types may be incorrectly represented (using the hidden _ambiguous_columns_split function).\n_ambiguous_columns_split: Separates numeric and categorical columns for a pandas Dataframe, and applies overrides for ambiguous cases via input. Hidden function used purely for all_distributions function."
  },
  {
    "objectID": "index.html#get-started",
    "href": "index.html#get-started",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "You can install this package into your preferred Python environment:\n# create a new empty conda environment with Python 3.11 (and pip by proxy):\nconda create -n eda_simplifier python=3.11 \n# activate the new environment\nconda activate eda_simplifier \nTo verify the package passes all the unit tests:\n# To install and use package (in edit mode with dev dependencies):\npip install -e \".[dev]\"  \n# Run unit tests:\npytest -v\n\n# Deactivate the conda environment when done:\nconda deactivate\nTODO: Add a brief example of how to use the package to this section\nTo use eda_simplifier in your code:\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from eda_simplifier.simplify import dataset_overview\n\n&gt;&gt;&gt; df = pd.DataFrame({\n    \"artist\": [\"A\", \"B\", \"C\"],\n    \"popularity\": [80, 75, None],\n    \"danceability\": [0.8, 0.6, 0.9]\n})\n\n&gt;&gt;&gt; summary = dataset_overview(df)"
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "Diana Cornescu\nJohnson Chuang\nLavanya Gupta\nTiantong Yin"
  },
  {
    "objectID": "index.html#copyright",
    "href": "index.html#copyright",
    "title": "Welcome to EDA_simplifier",
    "section": "",
    "text": "Copyright © Diana Cornescu, Johnson Chuang, Lavanya Gupta & Tiantong Yin.\nFree software distributed under the MIT License."
  },
  {
    "objectID": "reference/simplify._ambiguous_columns_split.html",
    "href": "reference/simplify._ambiguous_columns_split.html",
    "title": "simplify._ambiguous_columns_split",
    "section": "",
    "text": "simplify._ambiguous_columns_split(\n    pd_dataframe,\n    target_column,\n    ambiguous_column_types=None,\n)\nSeparates numeric and categorical columns for a pandas Dataframe, and applies overrides for ambiguous cases via input. Hidden function used purely for all_distributions function.\nThis function automatically classifies DataFrame columns as numeric or categorical based on their data types. Supports manual overrides when automatic classification is incorrect (e.g., a numeric zip code that should be treated as categorical).\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\npd_dataframe\npandas.DataFrame\nInput DataFrame to separate into numeric and categorical columns.\nrequired\n\n\ntarget_column\nstr\nThe name of the target column. Regardless of dtype, target column is included in both numeric and categorical outputs.\nrequired\n\n\nambiguous_column_types\ndict\nDictionary specifying column type overrides for ambiguous cases. Expected keys are “numeric” and “categorical”, each containing a list of column names to force into that category. Invalid or non-existent column names are silently ignored. Numeric definded as: int, float, and complex, including int/float 32/64, np.number and boolean columns too (Pandas behaviour). Categorical definded as: Non-numeric columns, including object, string, datetime, and categorical dtypes. Example: ambiguous_column_types = {“numeric”: [“year”], “categorical”: [“zip_code”]}\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nA dictionary with keys “numeric” and “categorical”, each containing a filtered DataFrame with only the columns of that type.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nValueError\nIf the input DataFrame is empty.\n\n\n\nValueError\nIf a column is specified in both “numeric” and “categorical” lists in ambiguous_column_types.\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'age': [25, 30, 35, 40],\n...     'income': [50000, 60000, 75000, 80000],\n...     'city': ['NYC', 'LA', 'Chicago', 'Boston'],\n...     'education': ['BS', 'MS', 'PhD', 'BS'],\n...     'approved': [True, False, True, True]\n... })\n&gt;&gt;&gt; result = _ambiguous_columns_split(\n...     pd_dataframe=df,\n...     target_column='approved'\n... )\n&gt;&gt;&gt; result['numeric'].columns\nIndex(['age', 'income', 'approved'], dtype='object')\n...\n&gt;&gt;&gt; result['categorical'].columns\nIndex(['city', 'education', 'approved'], dtype='object')"
  },
  {
    "objectID": "reference/simplify._ambiguous_columns_split.html#parameters",
    "href": "reference/simplify._ambiguous_columns_split.html#parameters",
    "title": "simplify._ambiguous_columns_split",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\npd_dataframe\npandas.DataFrame\nInput DataFrame to separate into numeric and categorical columns.\nrequired\n\n\ntarget_column\nstr\nThe name of the target column. Regardless of dtype, target column is included in both numeric and categorical outputs.\nrequired\n\n\nambiguous_column_types\ndict\nDictionary specifying column type overrides for ambiguous cases. Expected keys are “numeric” and “categorical”, each containing a list of column names to force into that category. Invalid or non-existent column names are silently ignored. Numeric definded as: int, float, and complex, including int/float 32/64, np.number and boolean columns too (Pandas behaviour). Categorical definded as: Non-numeric columns, including object, string, datetime, and categorical dtypes. Example: ambiguous_column_types = {“numeric”: [“year”], “categorical”: [“zip_code”]}\nNone"
  },
  {
    "objectID": "reference/simplify._ambiguous_columns_split.html#returns",
    "href": "reference/simplify._ambiguous_columns_split.html#returns",
    "title": "simplify._ambiguous_columns_split",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nA dictionary with keys “numeric” and “categorical”, each containing a filtered DataFrame with only the columns of that type."
  },
  {
    "objectID": "reference/simplify._ambiguous_columns_split.html#raises",
    "href": "reference/simplify._ambiguous_columns_split.html#raises",
    "title": "simplify._ambiguous_columns_split",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nValueError\nIf the input DataFrame is empty.\n\n\n\nValueError\nIf a column is specified in both “numeric” and “categorical” lists in ambiguous_column_types."
  },
  {
    "objectID": "reference/simplify._ambiguous_columns_split.html#examples",
    "href": "reference/simplify._ambiguous_columns_split.html#examples",
    "title": "simplify._ambiguous_columns_split",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     'age': [25, 30, 35, 40],\n...     'income': [50000, 60000, 75000, 80000],\n...     'city': ['NYC', 'LA', 'Chicago', 'Boston'],\n...     'education': ['BS', 'MS', 'PhD', 'BS'],\n...     'approved': [True, False, True, True]\n... })\n&gt;&gt;&gt; result = _ambiguous_columns_split(\n...     pd_dataframe=df,\n...     target_column='approved'\n... )\n&gt;&gt;&gt; result['numeric'].columns\nIndex(['age', 'income', 'approved'], dtype='object')\n...\n&gt;&gt;&gt; result['categorical'].columns\nIndex(['city', 'education', 'approved'], dtype='object')"
  },
  {
    "objectID": "reference/simplify.numeric.html",
    "href": "reference/simplify.numeric.html",
    "title": "simplify.numeric",
    "section": "",
    "text": "simplify.numeric(df, target='target')\nPerform exploratory data analysis (EDA) on numerical features in a dataset.\nThis function generates visualizations for numerical columns to help with initial exploratory analysis. It produces a missing values plot, box plots for each feature, distribution histograms, and a correlation matrix heatmap.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas DataFrame containing the numeric dataset to be analyzed.\nrequired\n\n\ntarget\nstr\nThe name of the target column.\n'target'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\ndict\nA dictionary containing Altair plot objects: - ‘missing_vals’: Bar chart showing missing value counts per column - ‘box_plot’: Box plots for each feature column - ‘distribution’: Histograms for each feature stacked vertically - ‘correlation’: Correlation matrix heatmap of features\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a pandas DataFrame or target is not a string\n\n\n\nValueError\nIf target name is not found in the DataFrame\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"popularity\": [80, 75, 90, 85],\n...     \"danceability\": [0.8, 0.6, 0.9, 0.7],\n...     \"energy\": [0.7, 0.8, 0.6, 0.9],\n...     \"target\": [1, 0, 0, 1]\n... })\n&gt;&gt;&gt; result = numeric(df, \"target\")\n&gt;&gt;&gt; result.keys()\ndict_keys(['missing_vals', 'box_plot', 'distribution', 'correlation'])"
  },
  {
    "objectID": "reference/simplify.numeric.html#parameters",
    "href": "reference/simplify.numeric.html#parameters",
    "title": "simplify.numeric",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas DataFrame containing the numeric dataset to be analyzed.\nrequired\n\n\ntarget\nstr\nThe name of the target column.\n'target'"
  },
  {
    "objectID": "reference/simplify.numeric.html#returns",
    "href": "reference/simplify.numeric.html#returns",
    "title": "simplify.numeric",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\ndict\nA dictionary containing Altair plot objects: - ‘missing_vals’: Bar chart showing missing value counts per column - ‘box_plot’: Box plots for each feature column - ‘distribution’: Histograms for each feature stacked vertically - ‘correlation’: Correlation matrix heatmap of features"
  },
  {
    "objectID": "reference/simplify.numeric.html#raises",
    "href": "reference/simplify.numeric.html#raises",
    "title": "simplify.numeric",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a pandas DataFrame or target is not a string\n\n\n\nValueError\nIf target name is not found in the DataFrame"
  },
  {
    "objectID": "reference/simplify.numeric.html#examples",
    "href": "reference/simplify.numeric.html#examples",
    "title": "simplify.numeric",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"popularity\": [80, 75, 90, 85],\n...     \"danceability\": [0.8, 0.6, 0.9, 0.7],\n...     \"energy\": [0.7, 0.8, 0.6, 0.9],\n...     \"target\": [1, 0, 0, 1]\n... })\n&gt;&gt;&gt; result = numeric(df, \"target\")\n&gt;&gt;&gt; result.keys()\ndict_keys(['missing_vals', 'box_plot', 'distribution', 'correlation'])"
  },
  {
    "objectID": "reference/simplify.categorical_plot.html",
    "href": "reference/simplify.categorical_plot.html",
    "title": "simplify.categorical_plot",
    "section": "",
    "text": "simplify.categorical_plot(\n    df,\n    target_column,\n    categorical_target,\n    max_categories=10,\n    categorical_features=None,\n)\nPerform EDA on categorical columns in a dataset.\nThis function creates Altair plots for the specified columns, assuming them to contain categorical data. It creates sorted horizontal bar charts to show the frequency and the proportion of each categories. Also create box plots for features vs target if the target is numerical, or stacked bar charts if the target is categorical.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas DataFrame containing the dataset\nrequired\n\n\ntarget_column\nstr\nThe name of the target column.\nrequired\n\n\ncategorical_target\nbool\nA boolean value indicating if the target column is categorical or not.\nrequired\n\n\nmax_categories\nint\nThe maximum categories to plot for high cardinality features\n10\n\n\ncategorical_features\nlist\nA list of strings containing column names of the categorical features. If this is not passed, keep all\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nlist\nA list of Altair plot objects of all the plots created\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a dataframe, target_column is not a string, or categorical_features is not a list\n\n\n\nValueError\nIf df is empty, target_column is not in the DataFrame, or categorical_features is empty or contains columns not in the DataFrame\n\n\n\n\n\n\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"artist\": [\"A\", \"B\", \"C\", \"D\"],\n...     \"popularity\": [80, 75, 90, 85],\n...     \"danceability\": [0.8, 0.6, 0.9, 0.7],\n...     \"energy\": [0.7, 0.8, 0.6, 0.9]\n... })\n&gt;&gt;&gt; plots = categorical_plot(df, 'popularity', False, categorical_features=[\"artist\"])"
  },
  {
    "objectID": "reference/simplify.categorical_plot.html#parameters",
    "href": "reference/simplify.categorical_plot.html#parameters",
    "title": "simplify.categorical_plot",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndf\npandas.DataFrame\nA pandas DataFrame containing the dataset\nrequired\n\n\ntarget_column\nstr\nThe name of the target column.\nrequired\n\n\ncategorical_target\nbool\nA boolean value indicating if the target column is categorical or not.\nrequired\n\n\nmax_categories\nint\nThe maximum categories to plot for high cardinality features\n10\n\n\ncategorical_features\nlist\nA list of strings containing column names of the categorical features. If this is not passed, keep all\nNone"
  },
  {
    "objectID": "reference/simplify.categorical_plot.html#returns",
    "href": "reference/simplify.categorical_plot.html#returns",
    "title": "simplify.categorical_plot",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nlist\nA list of Altair plot objects of all the plots created"
  },
  {
    "objectID": "reference/simplify.categorical_plot.html#raises",
    "href": "reference/simplify.categorical_plot.html#raises",
    "title": "simplify.categorical_plot",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nTypeError\nIf df is not a dataframe, target_column is not a string, or categorical_features is not a list\n\n\n\nValueError\nIf df is empty, target_column is not in the DataFrame, or categorical_features is empty or contains columns not in the DataFrame"
  },
  {
    "objectID": "reference/simplify.categorical_plot.html#examples",
    "href": "reference/simplify.categorical_plot.html#examples",
    "title": "simplify.categorical_plot",
    "section": "",
    "text": "&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = pd.DataFrame({\n...     \"artist\": [\"A\", \"B\", \"C\", \"D\"],\n...     \"popularity\": [80, 75, 90, 85],\n...     \"danceability\": [0.8, 0.6, 0.9, 0.7],\n...     \"energy\": [0.7, 0.8, 0.6, 0.9]\n... })\n&gt;&gt;&gt; plots = categorical_plot(df, 'popularity', False, categorical_features=[\"artist\"])"
  }
]